{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6812947a",
      "metadata": {
        "id": "6812947a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\shosh\\.conda\\envs\\Final_Project\\lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:913: UserWarning: Mixing V1 models and V2 models (or constructs, like `TypeAdapter`) is not supported. Please upgrade `BaseMessage` to V2.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain.tools import Tool\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain.prompts import PromptTemplate\n",
        "from openai import OpenAI\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import speech_recognition as sr\n",
        "from elevenlabs.client import ElevenLabs\n",
        "from elevenlabs import play"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "LYgedxpeAjrq",
      "metadata": {
        "id": "LYgedxpeAjrq"
      },
      "outputs": [],
      "source": [
        "# from zipfile import ZipFile\n",
        "# file = ZipFile('transcripts.zip', 'r')\n",
        "# file.extractall()\n",
        "# file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5248e133",
      "metadata": {
        "id": "5248e133"
      },
      "outputs": [],
      "source": [
        "# Stores chat message history in memory\n",
        "message_history = InMemoryChatMessageHistory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0b31b2e2",
      "metadata": {
        "id": "0b31b2e2"
      },
      "outputs": [],
      "source": [
        "# Load API keys from .env and initialize OpenAI and ElevenLabs clients\n",
        "load_dotenv()\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "client_voice = ElevenLabs(api_key=os.getenv(\"ELEVENLABS_API_KEY\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "wnF9YqdHMfLs",
      "metadata": {
        "id": "wnF9YqdHMfLs"
      },
      "outputs": [],
      "source": [
        "# Helper function to get chat completion from OpenAI API\n",
        "def chat_complete(client, system_message: str, user_message: str, model: str = \"gpt-3.5-turbo\"):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_message},\n",
        "            {\"role\": \"user\", \"content\": user_message}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9664aa27",
      "metadata": {
        "id": "9664aa27"
      },
      "outputs": [],
      "source": [
        "# Build a FAISS vector store from transcript text files\n",
        "def build_vectorstore_from_transcripts(folder_path, persist_path, openai_api_key):\n",
        "    docs = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            loader = TextLoader(os.path.join(folder_path, filename), encoding=\"utf-8\")\n",
        "            docs.extend(loader.load())\n",
        "\n",
        "    # Split documents into smaller chunks\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    split_docs = splitter.split_documents(docs)\n",
        "\n",
        "    # Generate vector embeddings and store them\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
        "    vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
        "    vectorstore.save_local(persist_path)\n",
        "    return vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b1052f4b",
      "metadata": {
        "id": "b1052f4b"
      },
      "outputs": [],
      "source": [
        "# Create a QA tool that answers based on vector similarity\n",
        "def create_qa_tool(vectorstore):\n",
        "    def qa_func(inputs):\n",
        "        query = inputs[\"__arg1\"]\n",
        "        messages = inputs.get(\"messages\", [])\n",
        "\n",
        "        chat_history_text = \"\\n\".join(\n",
        "            f\"{msg.type.upper()}: {msg.content}\" for msg in messages\n",
        "        )\n",
        "\n",
        "        # Find relevant documents\n",
        "        docs = vectorstore.similarity_search(query, k=5)\n",
        "        docs = [doc for doc in docs if doc.page_content.strip()]\n",
        "\n",
        "        # Similarity check between query and context\n",
        "        context_text = \"\\n\".join(doc.page_content for doc in docs)\n",
        "        if not docs or not context_text.strip():\n",
        "            return \"❗ This question is outside the scope of the cybersecurity playlist.\"\n",
        "\n",
        "        vectorizer = TfidfVectorizer().fit([query, context_text])\n",
        "        query_vec = vectorizer.transform([query])\n",
        "        context_vec = vectorizer.transform([context_text])\n",
        "        similarity_score = cosine_similarity(query_vec, context_vec)[0][0]\n",
        "\n",
        "        if similarity_score < 0.5 or len(context_text.split()) < 20:\n",
        "            return \"❗ This question is outside the scope of the cybersecurity playlist.\"\n",
        "        \n",
        "        # Generate a prompt for the model\n",
        "        prompt = PromptTemplate.from_template(\"\"\"\n",
        "        You are a cybersecurity tutor. ONLY answer based on the following:\n",
        "\n",
        "        Context:\n",
        "        {context}\n",
        "\n",
        "        Chat history:\n",
        "        {history}\n",
        "\n",
        "        Question:\n",
        "        {question}\n",
        "\n",
        "        If not related to cybersecurity, say: \"This question is outside the scope of the cybersecurity playlist.\"\n",
        "        \"\"\")\n",
        "\n",
        "        chain = (\n",
        "            {\"context\": lambda _: context_text, \"history\": lambda _: chat_history_text, \"question\": lambda _: query}\n",
        "            | prompt\n",
        "            | llm\n",
        "        )\n",
        "\n",
        "        return chain.invoke({}).content\n",
        "\n",
        "    return Tool(\n",
        "        name=\"CyberSecurityQA\",\n",
        "        func=qa_func,\n",
        "        description=\"Answer cybersecurity questions using vector context and chat history only.\"\n",
        "    )\n",
        "\n",
        "# Create a tool that generates multiple-choice cybersecurity quizzes\n",
        "def create_quiz_tool(vectorstore):\n",
        "    def quiz_func(query):\n",
        "        try:\n",
        "            num = int(query.strip())\n",
        "        except:\n",
        "            num = 3\n",
        "\n",
        "        # Get context for quiz generation\n",
        "        docs = vectorstore.similarity_search(\"cybersecurity\", k=5)\n",
        "        context = \"\\n\".join([doc.page_content for doc in docs])\n",
        "        prompt = PromptTemplate.from_template(\"\"\"\n",
        "        Generate {num_questions} cybersecurity multiple-choice questions based on the context below.\n",
        "        Each question should have 4 options (A-D), and do NOT include answers.\n",
        "\n",
        "        Context:\n",
        "        {context}\n",
        "        \"\"\")\n",
        "        chain = (\n",
        "            {\"context\": lambda x: context, \"num_questions\": lambda x: num}\n",
        "            | prompt\n",
        "            | llm\n",
        "        )\n",
        "        return chain.invoke({}).content\n",
        "\n",
        "    return Tool(\n",
        "        name=\"GenerateCyberQuiz\",\n",
        "        func=quiz_func,\n",
        "        description=\"Generate cybersecurity quizzes based on playlist content.\"\n",
        "    )\n",
        "\n",
        "# Combine tools into an agent with chat memory\n",
        "def create_agent_with_memory(vectorstore):\n",
        "    tools = [create_qa_tool(vectorstore), create_quiz_tool(vectorstore)]\n",
        "    agent = create_react_agent(model=llm, tools=tools)\n",
        "    return RunnableWithMessageHistory(\n",
        "        agent,\n",
        "        lambda: message_history,\n",
        "        input_messages_key=\"messages\",\n",
        "        history_messages_key=\"history\",\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "63ff4573",
      "metadata": {
        "id": "63ff4573"
      },
      "outputs": [],
      "source": [
        "# Print summary of the agent response\n",
        "def summarize_response(response):\n",
        "    print(\"\\n🗞 Summary:\")\n",
        "\n",
        "    system_message = \"\"\"\n",
        "    You are a strict filter that checks if a given paragraph is about cybersecurity.\n",
        "    Only respond with 'yes' if the paragraph clearly discusses cybersecurity topics such as network security, malware, encryption, firewalls, threats, or vulnerabilities.\n",
        "    If it does not relate to cybersecurity, respond with 'no'.\n",
        "    Respond with only 'yes' or 'no'. Do not explain.\n",
        "    \"\"\"\n",
        "    check_context = chat_complete(client, system_message=system_message, user_message=response['messages'][-1].content)\n",
        "\n",
        "    if check_context.lower() == 'no':\n",
        "        print(\"❌ This question is outside the scope of the cybersecurity playlist.\")\n",
        "        return\n",
        "\n",
        "    # Print user message\n",
        "    human_messages = [m for m in response['messages'] if m.type == \"human\"]\n",
        "    if human_messages:\n",
        "        print(f\"🧠 User: {human_messages[-1].content}\")\n",
        "\n",
        "    # Print tool used\n",
        "    tool_calls = [\n",
        "        m for m in response['messages'] \n",
        "        if hasattr(m, \"tool_calls\") and m.tool_calls\n",
        "    ]\n",
        "    if tool_calls:\n",
        "        print(\"🛠️ Tool Used:\", tool_calls[-1].tool_calls[0]['name'])\n",
        "\n",
        "    \n",
        "    final_answer = [\n",
        "        m for m in response['messages'] \n",
        "        if m.type == \"ai\" and m.content.strip() != \"\"\n",
        "    ]\n",
        "    if final_answer:\n",
        "        print(\"🤖 AI Response:\", final_answer[-1].content.strip())\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4df808f7",
      "metadata": {
        "id": "4df808f7"
      },
      "outputs": [],
      "source": [
        "# Main function for CLI interaction\n",
        "def run_cli():\n",
        "    vectorstore = FAISS.load_local(\n",
        "        \"vector_db\",\n",
        "        OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY),\n",
        "        allow_dangerous_deserialization=True\n",
        "    )\n",
        "\n",
        "    agent_with_history = create_agent_with_memory(vectorstore)\n",
        "\n",
        "    print(\"\\n🔐 Cybersecurity Agent Ready! Ask anything or request a quiz. Type 'exit' to quit.\\n\")\n",
        "\n",
        "    while True:\n",
        "        print(\"\\n⁉️ Choose input type: [1] Text   [2] Voice   [exit] to quit\")\n",
        "        mode = input(\"Your choice: \").strip().lower()\n",
        "\n",
        "        if mode in [\"exit\", \"quit\"]:\n",
        "            break\n",
        "\n",
        "        if mode == \"1\":\n",
        "            user_input = input(\"🧠 Your question: \")\n",
        "        elif mode == \"2\":\n",
        "            recognizer = sr.Recognizer()\n",
        "            with sr.Microphone() as source:\n",
        "                print(\"🎙️ Speak your question...\")\n",
        "                recognizer.adjust_for_ambient_noise(source)\n",
        "                audio = recognizer.listen(source)\n",
        "\n",
        "                try:\n",
        "                    user_input = recognizer.recognize_google(audio, language='en-US')\n",
        "                    print(\"📝 You said:\", user_input)\n",
        "                except sr.UnknownValueError:\n",
        "                    print(\"😕 Could not understand the audio.\")\n",
        "                    continue\n",
        "                except sr.RequestError:\n",
        "                    print(\"❌ Could not connect to speech service.\")\n",
        "                    continue\n",
        "        else:\n",
        "            print(\"⚠️ Invalid option. Please enter 1 or 2.\")\n",
        "            continue\n",
        "        \n",
        "        # Prepare messages and get response\n",
        "        previous_messages = message_history.messages[-5:]\n",
        "        new_message = HumanMessage(content=user_input)\n",
        "        all_messages = previous_messages + [new_message]\n",
        "\n",
        "        response = agent_with_history.invoke({\"messages\": all_messages})\n",
        "        summarize_response(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1fdf7f8a",
      "metadata": {
        "id": "1fdf7f8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔐 Cybersecurity Agent Ready! Ask anything or request a quiz. Type 'exit' to quit.\n",
            "\n",
            "\n",
            "⁉️ Choose input type: [1] Text   [2] Voice   [exit] to quit\n",
            "\n",
            "🗞 Summary:\n",
            "🧠 User: What is hashing?\n",
            "🛠️ Tool Used: CyberSecurityQA\n",
            "🤖 AI Response: Hashing is a process used in cybersecurity to convert data into a fixed-size string of characters, which is typically a sequence of numbers and letters. This transformation is done using a mathematical algorithm known as a hash function. The key characteristics of hashing include:\n",
            "\n",
            "1. **Deterministic**: The same input will always produce the same hash output.\n",
            "2. **Fixed Size**: Regardless of the size of the input data, the output hash will always be of a fixed size.\n",
            "3. **Fast Computation**: Hash functions can quickly compute the hash value for any given input.\n",
            "4. **Pre-image Resistance**: It should be computationally infeasible to reverse the process and retrieve the original input from its hash value.\n",
            "5. **Collision Resistance**: It should be unlikely that two different inputs will produce the same hash output.\n",
            "\n",
            "Hashing is commonly used for data integrity checks, password storage, and digital signatures, among other applications in cybersecurity.\n",
            "\n",
            "==================================================\n",
            "\n",
            "\n",
            "⁉️ Choose input type: [1] Text   [2] Voice   [exit] to quit\n",
            "⚠️ Invalid option. Please enter 1 or 2.\n",
            "\n",
            "⁉️ Choose input type: [1] Text   [2] Voice   [exit] to quit\n",
            "\n",
            "🗞 Summary:\n",
            "🧠 User: Explain the first one\n",
            "🛠️ Tool Used: CyberSecurityQA\n",
            "🤖 AI Response: The first characteristic of hashing, **Deterministic**, means that the same input will always produce the same hash output. This property is crucial for several reasons:\n",
            "\n",
            "1. **Consistency**: When you hash a piece of data (like a password or a file), you want to ensure that every time you hash that exact same data, you receive the same hash value. This consistency allows for reliable verification of data integrity.\n",
            "\n",
            "2. **Verification**: For example, when a user logs into a system, their entered password is hashed and compared to the stored hash. If the hashes match, it verifies that the correct password was entered without needing to store the actual password.\n",
            "\n",
            "3. **Data Integrity**: In scenarios where data integrity is critical, such as downloading files or transferring data, hashing can be used to ensure that the data has not been altered. By comparing the hash of the downloaded file to the original hash, users can confirm that the file is intact.\n",
            "\n",
            "Overall, the deterministic nature of hashing is fundamental to its effectiveness in cybersecurity, as it allows for reliable comparisons and verifications of data.\n",
            "\n",
            "==================================================\n",
            "\n",
            "\n",
            "⁉️ Choose input type: [1] Text   [2] Voice   [exit] to quit\n",
            "⚠️ Invalid option. Please enter 1 or 2.\n",
            "\n",
            "⁉️ Choose input type: [1] Text   [2] Voice   [exit] to quit\n",
            "\n",
            "🗞 Summary:\n",
            "❌ This question is outside the scope of the cybersecurity playlist.\n",
            "\n",
            "⁉️ Choose input type: [1] Text   [2] Voice   [exit] to quit\n"
          ]
        }
      ],
      "source": [
        "# Build the vector DB if it doesn't exist, then run CLI\n",
        "if not os.path.exists(\"vector_db\"):\n",
        "    build_vectorstore_from_transcripts(\"transcripts\", \"vector_db\", OPENAI_API_KEY)\n",
        "run_cli()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd328e31",
      "metadata": {},
      "source": [
        "# 🙏 Thanks 💙"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
